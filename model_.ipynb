{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2511a4112ca84725812569719356c671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62fb41d6e3b84adfba518ed9f59ca6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/myid/rk42218/dog'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "#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\n",
    "local_dir = \"./dog\"\n",
    "snapshot_download(\n",
    "    \"diffusers/dog-example\",\n",
    "    local_dir=local_dir,\n",
    "    repo_type=\"dataset\",\n",
    "    ignore_patterns=\".gitattributes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=\"CompVis/stable-diffusion-v1-4\"\n",
    "INSTANCE_DIR=\"./dog\"\n",
    "OUTPUT_DIR=\"./model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train_dreambooth.py [-h] --pretrained_model_name_or_path\n",
      "                           PRETRAINED_MODEL_NAME_OR_PATH [--revision REVISION]\n",
      "                           [--tokenizer_name TOKENIZER_NAME]\n",
      "                           --instance_data_dir INSTANCE_DATA_DIR\n",
      "                           [--class_data_dir CLASS_DATA_DIR] --instance_prompt\n",
      "                           INSTANCE_PROMPT [--class_prompt CLASS_PROMPT]\n",
      "                           [--with_prior_preservation]\n",
      "                           [--prior_loss_weight PRIOR_LOSS_WEIGHT]\n",
      "                           [--num_class_images NUM_CLASS_IMAGES]\n",
      "                           [--output_dir OUTPUT_DIR] [--seed SEED]\n",
      "                           [--resolution RESOLUTION] [--center_crop]\n",
      "                           [--train_text_encoder]\n",
      "                           [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                           [--sample_batch_size SAMPLE_BATCH_SIZE]\n",
      "                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                           [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                           [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                           [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                           [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                           [--gradient_checkpointing]\n",
      "                           [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                           [--lr_scheduler LR_SCHEDULER]\n",
      "                           [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                           [--lr_num_cycles LR_NUM_CYCLES]\n",
      "                           [--lr_power LR_POWER] [--use_8bit_adam]\n",
      "                           [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                           [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
      "                           [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                           [--adam_epsilon ADAM_EPSILON]\n",
      "                           [--max_grad_norm MAX_GRAD_NORM] [--push_to_hub]\n",
      "                           [--hub_token HUB_TOKEN]\n",
      "                           [--hub_model_id HUB_MODEL_ID]\n",
      "                           [--logging_dir LOGGING_DIR] [--allow_tf32]\n",
      "                           [--report_to REPORT_TO]\n",
      "                           [--validation_prompt VALIDATION_PROMPT]\n",
      "                           [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                           [--validation_steps VALIDATION_STEPS]\n",
      "                           [--mixed_precision {no,fp16,bf16}]\n",
      "                           [--prior_generation_precision {no,fp32,fp16,bf16}]\n",
      "                           [--local_rank LOCAL_RANK]\n",
      "                           [--enable_xformers_memory_efficient_attention]\n",
      "                           [--set_grads_to_none] [--offset_noise]\n",
      "                           [--snr_gamma SNR_GAMMA]\n",
      "                           [--pre_compute_text_embeddings]\n",
      "                           [--tokenizer_max_length TOKENIZER_MAX_LENGTH]\n",
      "                           [--text_encoder_use_attention_mask]\n",
      "                           [--skip_save_text_encoder]\n",
      "                           [--validation_images VALIDATION_IMAGES [VALIDATION_IMAGES ...]]\n",
      "                           [--class_labels_conditioning CLASS_LABELS_CONDITIONING]\n",
      "                           [--validation_scheduler {DPMSolverMultistepScheduler,DDPMScheduler}]\n",
      "train_dreambooth.py: error: unrecognized arguments: \\\n",
      "usage: train_dreambooth.py [-h] --pretrained_model_name_or_path\n",
      "                           PRETRAINED_MODEL_NAME_OR_PATH [--revision REVISION]\n",
      "                           [--tokenizer_name TOKENIZER_NAME]\n",
      "                           --instance_data_dir INSTANCE_DATA_DIR\n",
      "                           [--class_data_dir CLASS_DATA_DIR] --instance_prompt\n",
      "                           INSTANCE_PROMPT [--class_prompt CLASS_PROMPT]\n",
      "                           [--with_prior_preservation]\n",
      "                           [--prior_loss_weight PRIOR_LOSS_WEIGHT]\n",
      "                           [--num_class_images NUM_CLASS_IMAGES]\n",
      "                           [--output_dir OUTPUT_DIR] [--seed SEED]\n",
      "                           [--resolution RESOLUTION] [--center_crop]\n",
      "                           [--train_text_encoder]\n",
      "                           [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                           [--sample_batch_size SAMPLE_BATCH_SIZE]\n",
      "                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                           [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                           [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                           [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                           [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                           [--gradient_checkpointing]\n",
      "                           [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                           [--lr_scheduler LR_SCHEDULER]\n",
      "                           [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                           [--lr_num_cycles LR_NUM_CYCLES]\n",
      "                           [--lr_power LR_POWER] [--use_8bit_adam]\n",
      "                           [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                           [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
      "                           [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                           [--adam_epsilon ADAM_EPSILON]\n",
      "                           [--max_grad_norm MAX_GRAD_NORM] [--push_to_hub]\n",
      "                           [--hub_token HUB_TOKEN]\n",
      "                           [--hub_model_id HUB_MODEL_ID]\n",
      "                           [--logging_dir LOGGING_DIR] [--allow_tf32]\n",
      "                           [--report_to REPORT_TO]\n",
      "                           [--validation_prompt VALIDATION_PROMPT]\n",
      "                           [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                           [--validation_steps VALIDATION_STEPS]\n",
      "                           [--mixed_precision {no,fp16,bf16}]\n",
      "                           [--prior_generation_precision {no,fp32,fp16,bf16}]\n",
      "                           [--local_rank LOCAL_RANK]\n",
      "                           [--enable_xformers_memory_efficient_attention]\n",
      "                           [--set_grads_to_none] [--offset_noise]\n",
      "                           [--snr_gamma SNR_GAMMA]\n",
      "                           [--pre_compute_text_embeddings]\n",
      "                           [--tokenizer_max_length TOKENIZER_MAX_LENGTH]\n",
      "                           [--text_encoder_use_attention_mask]\n",
      "                           [--skip_save_text_encoder]\n",
      "                           [--validation_images VALIDATION_IMAGES [VALIDATION_IMAGES ...]]\n",
      "                           [--class_labels_conditioning CLASS_LABELS_CONDITIONING]\n",
      "                           [--validation_scheduler {DPMSolverMultistepScheduler,DDPMScheduler}]\n",
      "train_dreambooth.py: error: unrecognized arguments: \\\n",
      "usage: train_dreambooth.py [-h] --pretrained_model_name_or_path\n",
      "                           PRETRAINED_MODEL_NAME_OR_PATH [--revision REVISION]\n",
      "                           [--tokenizer_name TOKENIZER_NAME]\n",
      "                           --instance_data_dir INSTANCE_DATA_DIR\n",
      "                           [--class_data_dir CLASS_DATA_DIR] --instance_prompt\n",
      "                           INSTANCE_PROMPT [--class_prompt CLASS_PROMPT]\n",
      "                           [--with_prior_preservation]\n",
      "                           [--prior_loss_weight PRIOR_LOSS_WEIGHT]\n",
      "                           [--num_class_images NUM_CLASS_IMAGES]\n",
      "                           [--output_dir OUTPUT_DIR] [--seed SEED]\n",
      "                           [--resolution RESOLUTION] [--center_crop]\n",
      "                           [--train_text_encoder]\n",
      "                           [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                           [--sample_batch_size SAMPLE_BATCH_SIZE]\n",
      "                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                           [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                           [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                           [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                           [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                           [--gradient_checkpointing]\n",
      "                           [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                           [--lr_scheduler LR_SCHEDULER]\n",
      "                           [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                           [--lr_num_cycles LR_NUM_CYCLES]\n",
      "                           [--lr_power LR_POWER] [--use_8bit_adam]\n",
      "                           [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                           [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
      "                           [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                           [--adam_epsilon ADAM_EPSILON]\n",
      "                           [--max_grad_norm MAX_GRAD_NORM] [--push_to_hub]\n",
      "                           [--hub_token HUB_TOKEN]\n",
      "                           [--hub_model_id HUB_MODEL_ID]\n",
      "                           [--logging_dir LOGGING_DIR] [--allow_tf32]\n",
      "                           [--report_to REPORT_TO]\n",
      "                           [--validation_prompt VALIDATION_PROMPT]\n",
      "                           [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                           [--validation_steps VALIDATION_STEPS]\n",
      "                           [--mixed_precision {no,fp16,bf16}]\n",
      "                           [--prior_generation_precision {no,fp32,fp16,bf16}]\n",
      "                           [--local_rank LOCAL_RANK]\n",
      "                           [--enable_xformers_memory_efficient_attention]\n",
      "                           [--set_grads_to_none] [--offset_noise]\n",
      "                           [--snr_gamma SNR_GAMMA]\n",
      "                           [--pre_compute_text_embeddings]\n",
      "                           [--tokenizer_max_length TOKENIZER_MAX_LENGTH]\n",
      "                           [--text_encoder_use_attention_mask]\n",
      "                           [--skip_save_text_encoder]\n",
      "                           [--validation_images VALIDATION_IMAGES [VALIDATION_IMAGES ...]]\n",
      "                           [--class_labels_conditioning CLASS_LABELS_CONDITIONING]\n",
      "                           [--validation_scheduler {DPMSolverMultistepScheduler,DDPMScheduler}]\n",
      "train_dreambooth.py: error: unrecognized arguments: \\\n",
      "usage: train_dreambooth.py [-h] --pretrained_model_name_or_path\n",
      "                           PRETRAINED_MODEL_NAME_OR_PATH [--revision REVISION]\n",
      "                           [--tokenizer_name TOKENIZER_NAME]\n",
      "                           --instance_data_dir INSTANCE_DATA_DIR\n",
      "                           [--class_data_dir CLASS_DATA_DIR] --instance_prompt\n",
      "                           INSTANCE_PROMPT [--class_prompt CLASS_PROMPT]\n",
      "                           [--with_prior_preservation]\n",
      "                           [--prior_loss_weight PRIOR_LOSS_WEIGHT]\n",
      "                           [--num_class_images NUM_CLASS_IMAGES]\n",
      "                           [--output_dir OUTPUT_DIR] [--seed SEED]\n",
      "                           [--resolution RESOLUTION] [--center_crop]\n",
      "                           [--train_text_encoder]\n",
      "                           [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                           [--sample_batch_size SAMPLE_BATCH_SIZE]\n",
      "                           [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                           [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                           [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                           [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                           [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                           [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                           [--gradient_checkpointing]\n",
      "                           [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                           [--lr_scheduler LR_SCHEDULER]\n",
      "                           [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                           [--lr_num_cycles LR_NUM_CYCLES]\n",
      "                           [--lr_power LR_POWER] [--use_8bit_adam]\n",
      "                           [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                           [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\n",
      "                           [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                           [--adam_epsilon ADAM_EPSILON]\n",
      "                           [--max_grad_norm MAX_GRAD_NORM] [--push_to_hub]\n",
      "                           [--hub_token HUB_TOKEN]\n",
      "                           [--hub_model_id HUB_MODEL_ID]\n",
      "                           [--logging_dir LOGGING_DIR] [--allow_tf32]\n",
      "                           [--report_to REPORT_TO]\n",
      "                           [--validation_prompt VALIDATION_PROMPT]\n",
      "                           [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                           [--validation_steps VALIDATION_STEPS]\n",
      "                           [--mixed_precision {no,fp16,bf16}]\n",
      "                           [--prior_generation_precision {no,fp32,fp16,bf16}]\n",
      "                           [--local_rank LOCAL_RANK]\n",
      "                           [--enable_xformers_memory_efficient_attention]\n",
      "                           [--set_grads_to_none] [--offset_noise]\n",
      "                           [--snr_gamma SNR_GAMMA]\n",
      "                           [--pre_compute_text_embeddings]\n",
      "                           [--tokenizer_max_length TOKENIZER_MAX_LENGTH]\n",
      "                           [--text_encoder_use_attention_mask]\n",
      "                           [--skip_save_text_encoder]\n",
      "                           [--validation_images VALIDATION_IMAGES [VALIDATION_IMAGES ...]]\n",
      "                           [--class_labels_conditioning CLASS_LABELS_CONDITIONING]\n",
      "                           [--validation_scheduler {DPMSolverMultistepScheduler,DDPMScheduler}]\n",
      "train_dreambooth.py: error: unrecognized arguments: \\\n",
      "[2023-11-11 17:28:23,754] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 1608889) of binary: /home/myid/rk42218/miniconda3/envs/img2img/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 985, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 654, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/run.py\", line 797, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "./diffusers/examples/dreambooth/train_dreambooth.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2023-11-11_17:28:23\n",
      "  host      : csci-cscuda\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 2 (pid: 1608890)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2023-11-11_17:28:23\n",
      "  host      : csci-cscuda\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 2 (pid: 1608891)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[3]:\n",
      "  time      : 2023-11-11_17:28:23\n",
      "  host      : csci-cscuda\n",
      "  rank      : 3 (local_rank: 3)\n",
      "  exitcode  : 2 (pid: 1608892)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2023-11-11_17:28:23\n",
      "  host      : csci-cscuda\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 2 (pid: 1608889)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --instance_prompt=\"a photo of sks dog\" \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=5e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=400 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511354507f0f4ff9819a61ff7776e166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec7b2306d88408691a0e2f94d46f1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Load the pre-trained Stable Diffusion model\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=True)\n",
    "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load your input image\n",
    "input_image_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png\"  # Replace with your image URL\n",
    "response = requests.get(input_image_url)\n",
    "input_image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Define your text prompt\n",
    "prompt = \"Black Gackground of cat, cat remains the same\"  # Replace with your text prompt\n",
    "\n",
    "# Generate an image\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output_image = pipe(prompt=prompt, init_image=input_image, strength=0.75).images[0]  # Adjust strength as needed\n",
    "\n",
    "# Save or display the output image\n",
    "output_image.save(\"output.png\")\n",
    "output_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d9564fa69f434198552ec3dc49bea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'timestep' and 'encoder_hidden_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y305sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y305sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y305sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     outputs \u001b[39m=\u001b[39m unet(inputs)  \u001b[39m# Forward pass\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y305sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m     loss \u001b[39m=\u001b[39m some_loss_function(outputs, target_outputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y305sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'timestep' and 'encoder_hidden_states'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import AdamW\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Set device to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained Stable Diffusion model\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=True)\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "# Access the UNet component\n",
    "unet = pipe.unet\n",
    "unet.to(device)\n",
    "unet.train()  # Set the UNet model to training mode\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize images (if necessary)\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_paths, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.file_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Dataset and DataLoader setup\n",
    "dataset_path = \"./finaldata/train_merged/post/\"  # Replace with your dataset path\n",
    "file_paths = [str(p) for p in Path(dataset_path).glob(\"*.png\")]\n",
    "dataset = CustomImageDataset(file_paths, transform=transform)\n",
    "train_dataloader = DataLoader(dataset, shuffle=True, batch_size=4)  # Adjust batch size as needed\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = AdamW(unet.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = unet(inputs)  # Forward pass\n",
    "        loss = some_loss_function(outputs, target_outputs)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Saving the model\n",
    "unet_save_path = \"./model\"\n",
    "torch.save(unet.state_dict(), unet_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.distributed' has no attribute 'nccl_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y302sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mif\u001b[39;00m dist\u001b[39m.\u001b[39mis_nccl_available():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y302sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNCCL is available\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y302sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNCCL version:\u001b[39m\u001b[39m\"\u001b[39m, dist\u001b[39m.\u001b[39;49mnccl_version())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y302sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y302sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNCCL is not available\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.distributed' has no attribute 'nccl_version'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "# Check if NCCL is available and its version\n",
    "if dist.is_nccl_available():\n",
    "    print(\"NCCL is available\")\n",
    "    print(\"NCCL version:\", dist.nccl_version())\n",
    "else:\n",
    "    print(\"NCCL is not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the NCCL repository\n",
    "git clone https://github.com/NVIDIA/nccl-tests.git\n",
    "\n",
    "# Change to the nccl-tests directory\n",
    "cd nccl-tests\n",
    "\n",
    "# Build the tests\n",
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def generate_description(filename):\n",
    "    # Split the filename to extract relevant parts\n",
    "    parts = filename.split('_')\n",
    "    disaster_name = parts[0].replace('-', ' ').title()  # Convert to title case\n",
    "    phase = 'Pre' if 'pre' in filename else 'Post'\n",
    "    return f\"{phase} Disaster Satellite Image of {disaster_name}\"\n",
    "\n",
    "def generate_json(directory):\n",
    "    data = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".png\"):  # Check if it's a PNG image\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            description = generate_description(filename)\n",
    "            data[file_path] = description\n",
    "    \n",
    "    # Writing to a JSON file\n",
    "    with open('image_descriptions.json', 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "# Replace 'your_directory_path' with the path of your directory\n",
    "directory_path = './finaldata/train_merged/post/'\n",
    "generate_json(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'INFO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y306sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m NCCL_DEBUG\u001b[39m=\u001b[39mINFO\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y306sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y306sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'INFO' is not defined"
     ]
    }
   ],
   "source": [
    "NCCL_DEBUG=INFO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Create a simple dataset\n",
    "inputs = torch.randn(100, 10)\n",
    "targets = torch.randint(0, 2, (100,))\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Initialize the model and wrap it with DataParallel\n",
    "model = SimpleNet()\n",
    "model = DataParallel(model)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):  # just 2 epochs for testing\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "print(\"Training complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-16yiq2um\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-16yiq2um\n",
      "  Resolved https://github.com/huggingface/transformers to commit 7ee995fd9c692761c4601ddbffa2ac2ec9f27b0b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers==4.36.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: fsspec in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.36.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.36.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->transformers==4.36.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->transformers==4.36.0.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.36.0.dev0-py3-none-any.whl size=7987409 sha256=90bca245e1068ee4e3054d3daa3a9b038aa263c5637c33e2195e874d9b03dcd1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g7__7340/wheels/42/68/45/c63edff61c292f2dfd4df4ef6522dcbecc603e7af82813c1d7\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.0\n",
      "    Uninstalling transformers-4.35.0:\n",
      "      Successfully uninstalled transformers-4.35.0\n",
      "Successfully installed transformers-4.36.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading model: CompVis/stable-diffusion-v1-4 does not appear to have a file named config.json. Checkout 'https://huggingface.co/CompVis/stable-diffusion-v1-4/main' for available files.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/CompVis/stable-diffusion-v1-4/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    431\u001b[0m         path_or_repo_id,\n\u001b[1;32m    432\u001b[0m         filename,\n\u001b[1;32m    433\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    434\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    435\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    436\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    437\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    438\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    439\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    440\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    441\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    442\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1232\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1233\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1234\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1235\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1236\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1237\u001b[0m     )\n\u001b[1;32m   1238\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1239\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/file_download.py:1608\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1599\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1600\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1601\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1606\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m   1607\u001b[0m )\n\u001b[0;32m-> 1608\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1610\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:271\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    270\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEntry Not Found for url: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mraise\u001b[39;00m EntryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGatedRepo\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-655005c1-6a87156134c8feab6fb338b0;d89ad0a5-db9a-4e25-b0bf-7b79ce27ebe3)\n\nEntry Not Found for url: https://huggingface.co/CompVis/stable-diffusion-v1-4/resolve/main/config.json.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mCompVis/stable-diffusion-v1-4\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     model \u001b[39m=\u001b[39m VisionEncoderDecoderModel\u001b[39m.\u001b[39mfrom_encoder_decoder_pretrained(\u001b[39m\"\u001b[39m\u001b[39mgoogle/vit-base-patch16-224-in21k\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCompVis/stable-diffusion-v1-4\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:735\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 735\u001b[0m     config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    736\u001b[0m         pretrained_model_name_or_path, trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    737\u001b[0m     )\n\u001b[1;32m    738\u001b[0m config_tokenizer_class \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mtokenizer_class\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:1054\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m code_revision \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcode_revision\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1054\u001b[0m config_dict, unused_kwargs \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1055\u001b[0m has_remote_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/configuration_utils.py:622\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/configuration_utils.py:677\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    676\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    678\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    679\u001b[0m         configuration_file,\n\u001b[1;32m    680\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    681\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    682\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    683\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    684\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    685\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    686\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    687\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    688\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    689\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/utils/hub.py:481\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m         revision \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 481\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m does not appear to have a file named \u001b[39m\u001b[39m{\u001b[39;00mfull_filename\u001b[39m}\u001b[39;00m\u001b[39m. Checkout \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for available files.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    484\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    486\u001b[0m     \u001b[39m# First we try to see if we have a cached version (not up to date):\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: CompVis/stable-diffusion-v1-4 does not appear to have a file named config.json. Checkout 'https://huggingface.co/CompVis/stable-diffusion-v1-4/main' for available files.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mError loading model:\u001b[39m\u001b[39m\"\u001b[39m, e, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     sys\u001b[39m.\u001b[39;49mexit(\u001b[39m1\u001b[39;49m)  \u001b[39m# Exit the script if the model fails to load\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X45sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Function to load and preprocess the images\u001b[39;00m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[1;32m   2093\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2094\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 2095\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[1;32m   2096\u001b[0m                                                      value))\n\u001b[1;32m   2097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2098\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   2099\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/IPython/core/ultratb.py:696\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[1;32m    689\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/IPython/core/ultratb.py:559\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    556\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[1;32m    557\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    558\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 559\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m    560\u001b[0m             etype,\n\u001b[1;32m    561\u001b[0m             evalue,\n\u001b[1;32m    562\u001b[0m             (etb, chained_exc_ids),  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    563\u001b[0m             chained_exceptions_tb_offset,\n\u001b[1;32m    564\u001b[0m             context,\n\u001b[1;32m    565\u001b[0m         )\n\u001b[1;32m    566\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[1;32m    567\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[1;32m    569\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/IPython/core/ultratb.py:1396\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1395\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m etb\n\u001b[0;32m-> 1396\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1397\u001b[0m     \u001b[39mself\u001b[39;49m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1398\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/IPython/core/ultratb.py:1287\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1284\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m   1285\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[1;32m   1286\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1288\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1289\u001b[0m     )\n\u001b[1;32m   1290\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1291\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/IPython/core/ultratb.py:1140\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[1;32m   1132\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1133\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[1;32m   1138\u001b[0m ):\n\u001b[1;32m   1139\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1140\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m   1141\u001b[0m                                                            tb_offset)\n\u001b[1;32m   1143\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/IPython/core/ultratb.py:1030\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[1;32m   1028\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(\u001b[39mstr\u001b[39m(etype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[1;32m   1029\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1030\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1033\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m   1034\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/IPython/core/ultratb.py:1098\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[39mwhile\u001b[39;00m cf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m         mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(cf\u001b[39m.\u001b[39;49mtb_frame)\n\u001b[1;32m   1099\u001b[0m         \u001b[39mif\u001b[39;00m mod \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m             mod_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import AutoTokenizer, VisionEncoderDecoderModel, TrainingArguments, Trainer, default_data_collator\n",
    "from torch.utils.data import Dataset\n",
    "import sys\n",
    "\n",
    "from transformers import AutoTokenizer, VisionEncoderDecoderModel\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "    model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"google/vit-base-patch16-224-in21k\", \"CompVis/stable-diffusion-v1-4\")\n",
    "    print(\"Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Error loading model:\", e, file=sys.stderr)\n",
    "    sys.exit(1)  # Exit the script if the model fails to load\n",
    "\n",
    "# Function to load and preprocess the images\n",
    "def load_image(image_path):\n",
    "    return Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Load your dataset\n",
    "with open('./image_descriptions.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "images = []\n",
    "texts = []\n",
    "\n",
    "for image_path, text in data.items():\n",
    "    images.append(load_image(image_path))\n",
    "    texts.append(text)\n",
    "\n",
    "# Preprocess and tokenize text\n",
    "inputs = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(torch.long) for k, v in inputs.items()}\n",
    "\n",
    "# Preprocess images\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "images = torch.stack([image_transform(image) for image in images])\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, inputs):\n",
    "        self.images = images\n",
    "        self.inputs = inputs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"pixel_values\": self.images[idx], \"input_ids\": self.inputs[\"input_ids\"][idx], \"attention_mask\": self.inputs[\"attention_mask\"][idx]}\n",
    "\n",
    "# Custom dataset instance\n",
    "dataset = CustomDataset(images, inputs)\n",
    "\n",
    "# Define a custom data collator\n",
    "data_collator = default_data_collator\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os \n",
    "size = (512, 512)\n",
    "\n",
    "# get all the files in a folder, make sure all are image files\n",
    "files = glob.glob('./dog/raw/*')\n",
    "\n",
    "for fil in files:\n",
    "    # implement file type checking here if required\n",
    "    \n",
    "    # get the basename, e.g. \"dragon.jpg\" -> (\"dragon\", \".jpg\")\n",
    "    basename = os.path.splitext(os.path.basename(fil))[0]\n",
    "\n",
    "    with Image.open(fil) as img:\n",
    "        # resize the image to 512 x 512\n",
    "        img = img.resize(size)\n",
    "        \n",
    "        # rotate the image if required\n",
    "        # img = img.rotate(90)\n",
    "        \n",
    "        # save the resized image, modify the resample method if required, modify the output directory as well\n",
    "        img.save(f\"./dog/key/{basename}.png\", format=\"PNG\", resample=Image.Resampling.NEAREST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home/myid/rk42218/miniconda3\n",
      "img2img               *  /home/myid/rk42218/miniconda3/envs/img2img\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda info --envs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'content-trust', 'doctor', 'repoquery', 'env')\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate img2img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define data transformations (e.g., resizing, normalization)\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((224, 224)),  # Resize images to a standard size\n",
    "    transforms.ToTensor(),         # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize pixel values\n",
    "])\n",
    "\n",
    "# Define paths to your train and validation data\n",
    "train_data_path =r\"./finaldata/train/\"\n",
    "val_data_path =r\"./finaldata/val/\"\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = ImageFolder(root=train_data_path, transform=transform)\n",
    "val_dataset = ImageFolder(root=val_data_path, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "Loading pipeline components...:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 6/7 [00:43<00:07,  7.03s/it]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:57<00:00,  8.26s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StableDiffusionImg2ImgPipeline' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Define loss function and optimizer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(pipe\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Training loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/diffusers/configuration_utils.py:137\u001b[0m, in \u001b[0;36mConfigMixin.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    134\u001b[0m     deprecate(\u001b[39m\"\u001b[39m\u001b[39mdirect config name access\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m1.0.0\u001b[39m\u001b[39m\"\u001b[39m, deprecation_message, standard_warn\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_dict[name]\n\u001b[0;32m--> 137\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StableDiffusionImg2ImgPipeline' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "\n",
    "\n",
    "# Assuming you have defined train_loader and val_loader as in the previous message\n",
    "#device = \"cuda\"\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Define the model\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(pipe.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    pipe.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pipe(inputs.to(device))\n",
    "        loss = criterion(outputs, targets.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    pipe.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = pipe(inputs.to(device))\n",
    "            loss = criterion(outputs, targets.to(device))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss/len(val_loader)}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(pipe.state_dict(), 'trained_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./finaldata/train/train_pre_prompts.csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the directory path where images are stored\n",
    "image_dir = \"./finaldata/train/pre/\"\n",
    "\n",
    "# Define the path for the CSV file you want to create\n",
    "csv_file_path = \"./finaldata/train/train_pre_prompts.csv\"\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = os.listdir(image_dir)\n",
    "\n",
    "# Process the files and write to CSV\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File Name', 'Description'])  # Write the header row\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith(\".png\"):  # Check if the file is a PNG image\n",
    "            # Extract the base name (without _post_disaster_left.png)\n",
    "            base_name = filename.split('_')[0]\n",
    "            # Replace dashes with spaces and capitalize each word for the description\n",
    "            description = 'Pre Disaster Satellite Image of ' + base_name.replace('-', ' ').title()\n",
    "            # Write the original file name and the description to the CSV\n",
    "            writer.writerow([filename, description])\n",
    "\n",
    "# Output the path to the CSV file\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./finaldata/train/train_post_prompts.csv'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the directory path where images are stored\n",
    "image_dir = \"./finaldata/train/post/\"\n",
    "\n",
    "# Define the path for the CSV file you want to create\n",
    "csv_file_path = \"./finaldata/train/train_post_prompts.csv\"\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = os.listdir(image_dir)\n",
    "\n",
    "# Process the files and write to CSV\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File Name', 'Description'])  # Write the header row\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith(\".png\"):  # Check if the file is a PNG image\n",
    "            # Extract the base name (without _post_disaster_left.png)\n",
    "            base_name = filename.split('_')[0]\n",
    "            # Replace dashes with spaces and capitalize each word for the description\n",
    "            description = 'Post Disaster Satellite Image of ' + base_name.replace('-', ' ').title()\n",
    "            # Write the original file name and the description to the CSV\n",
    "            writer.writerow([filename, description])\n",
    "\n",
    "# Output the path to the CSV file\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./finaldata/val/val_post_prompts.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the directory path where images are stored\n",
    "image_dir = \"./finaldata/val/post/\"\n",
    "\n",
    "# Define the path for the CSV file you want to create\n",
    "csv_file_path = \"./finaldata/val/val_post_prompts.csv\"\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = os.listdir(image_dir)\n",
    "\n",
    "# Process the files and write to CSV\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File Name', 'Description'])  # Write the header row\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith(\".png\"):  # Check if the file is a PNG image\n",
    "            # Extract the base name (without _post_disaster_left.png)\n",
    "            base_name = filename.split('_')[0]\n",
    "            # Replace dashes with spaces and capitalize each word for the description\n",
    "            description = 'Post Disaster Satellite Image of ' + base_name.replace('-', ' ').title()\n",
    "            # Write the original file name and the description to the CSV\n",
    "            writer.writerow([filename, description])\n",
    "\n",
    "# Output the path to the CSV file\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./finaldata/val/val_pre_prompts.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the directory path where images are stored\n",
    "image_dir = \"./finaldata/val/pre/\"\n",
    "\n",
    "# Define the path for the CSV file you want to create\n",
    "csv_file_path = \"./finaldata/val/val_pre_prompts.csv\"\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = os.listdir(image_dir)\n",
    "\n",
    "# Process the files and write to CSV\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File Name', 'Description'])  # Write the header row\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith(\".png\"):  # Check if the file is a PNG image\n",
    "            # Extract the base name (without _post_disaster_left.png)\n",
    "            base_name = filename.split('_')[0]\n",
    "            # Replace dashes with spaces and capitalize each word for the description\n",
    "            description = 'Pre Disaster Satellite Image of ' + base_name.replace('-', ' ').title()\n",
    "            # Write the original file name and the description to the CSV\n",
    "            writer.writerow([filename, description])\n",
    "\n",
    "# Output the path to the CSV file\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./finaldata/train/train_merged_prompts.csv'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the directory path where images are stored\n",
    "image_dir = \"./finaldata/train_merged/\"\n",
    "\n",
    "# Define the path for the CSV file you want to create\n",
    "csv_file_path = \"./finaldata/train/train_merged_prompts.csv\"\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = os.listdir(image_dir)\n",
    "\n",
    "# Process the files and write to CSV\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File Name', 'Description'])  # Write the header row\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith(\".png\"):  # Check if the file is a PNG image\n",
    "            # Extract the base name (without _post_disaster_left.png)\n",
    "            base_name = filename.split('_')[0]\n",
    "            # Replace dashes with spaces and capitalize each word for the description\n",
    "            description = 'Pre Disaster Satellite Image of ' + base_name.replace('-', ' ').title()\n",
    "            # Write the original file name and the description to the CSV\n",
    "            writer.writerow([filename, description])\n",
    "\n",
    "# Output the path to the CSV file\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./finaldata/val_merged/val_merged_prompts.csv'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the directory path where images are stored\n",
    "image_dir = \"./finaldata/val_merged/\"\n",
    "\n",
    "# Define the path for the CSV file you want to create\n",
    "csv_file_path = \"./finaldata/val_merged/val_merged_prompts.csv\"\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = os.listdir(image_dir)\n",
    "\n",
    "# Process the files and write to CSV\n",
    "with open(csv_file_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['File Name', 'Description'])  # Write the header row\n",
    "\n",
    "    for filename in file_list:\n",
    "        if filename.endswith(\".png\"):  # Check if the file is a PNG image\n",
    "            # Extract the base name (without _post_disaster_left.png)\n",
    "            base_name = filename.split('_')[0]\n",
    "            # Replace dashes with spaces and capitalize each word for the description\n",
    "            description = 'Pre Disaster Satellite Image of ' + base_name.replace('-', ' ').title()\n",
    "            # Write the original file name and the description to the CSV\n",
    "            writer.writerow([filename, description])\n",
    "\n",
    "# Output the path to the CSV file\n",
    "csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76c39c409a94f0399ab332dbf5b819a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4859 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613032ec161b4a078d2fb626d03b157a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4859 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c2eaa374e641b6a8c548f52d6b6f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d47e3e8ffd0471fafe61b0088e912c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042d060dc3984cc49f1fc36c762f3150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# example 1: local folder\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"./finaldata/train_merged/post/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed7c87fb244454397ddcc8dc385ef22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HTTPError",
     "evalue": "Invalid user token. If you didn't pass a user token, make sure you are properly logged in by executing `huggingface-cli login`, and if you did pass a user token, double-check it's correct.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/whoami-v2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/hf_api.py:954\u001b[0m, in \u001b[0;36mHfApi.whoami\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 954\u001b[0m     hf_raise_for_status(r)\n\u001b[1;32m    955\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:293\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    286\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m make sure you are authenticated.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-654d46c8-66d1acdb380e22ad0c3c8c3c;70bdca86-b315-4163-b774-ec527c6fa98f)\n\nRepository Not Found for url: https://huggingface.co/api/whoami-v2.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 32\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y215sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m notebook_login()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y215sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# if you want to push to a private repo, simply pass private=True:\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y215sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dataset\u001b[39m.\u001b[39;49mpush_to_hub(\u001b[39m\"\u001b[39;49m\u001b[39mimagefolder\u001b[39;49m\u001b[39m\"\u001b[39;49m, private\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/datasets/dataset_dict.py:1641\u001b[0m, in \u001b[0;36mDatasetDict.push_to_hub\u001b[0;34m(self, repo_id, config_name, private, token, branch, max_shard_size, num_shards, embed_external_files)\u001b[0m\n\u001b[1;32m   1639\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPushing split \u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m to the Hub.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1640\u001b[0m \u001b[39m# The split=key needs to be removed before merging\u001b[39;00m\n\u001b[0;32m-> 1641\u001b[0m repo_id, split, uploaded_size, dataset_nbytes, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m[split]\u001b[39m.\u001b[39;49m_push_parquet_shards_to_hub(\n\u001b[1;32m   1642\u001b[0m     repo_id,\n\u001b[1;32m   1643\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1644\u001b[0m     split\u001b[39m=\u001b[39;49msplit,\n\u001b[1;32m   1645\u001b[0m     private\u001b[39m=\u001b[39;49mprivate,\n\u001b[1;32m   1646\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1647\u001b[0m     branch\u001b[39m=\u001b[39;49mbranch,\n\u001b[1;32m   1648\u001b[0m     max_shard_size\u001b[39m=\u001b[39;49mmax_shard_size,\n\u001b[1;32m   1649\u001b[0m     num_shards\u001b[39m=\u001b[39;49mnum_shards\u001b[39m.\u001b[39;49mget(split),\n\u001b[1;32m   1650\u001b[0m     embed_external_files\u001b[39m=\u001b[39;49membed_external_files,\n\u001b[1;32m   1651\u001b[0m )\n\u001b[1;32m   1652\u001b[0m total_uploaded_size \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m uploaded_size\n\u001b[1;32m   1653\u001b[0m total_dataset_nbytes \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dataset_nbytes\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/datasets/arrow_dataset.py:5237\u001b[0m, in \u001b[0;36mDataset._push_parquet_shards_to_hub\u001b[0;34m(self, repo_id, data_dir, split, private, token, branch, max_shard_size, num_shards, embed_external_files)\u001b[0m\n\u001b[1;32m   5235\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(identifier) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   5236\u001b[0m     dataset_name \u001b[39m=\u001b[39m identifier[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 5237\u001b[0m     organization_or_username \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49mwhoami(token)[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   5238\u001b[0m     repo_id \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00morganization_or_username\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   5240\u001b[0m api\u001b[39m.\u001b[39mcreate_repo(\n\u001b[1;32m   5241\u001b[0m     repo_id,\n\u001b[1;32m   5242\u001b[0m     token\u001b[39m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5245\u001b[0m     exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   5246\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/hf_api.py:956\u001b[0m, in \u001b[0;36mHfApi.whoami\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    954\u001b[0m     hf_raise_for_status(r)\n\u001b[1;32m    955\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 956\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(\n\u001b[1;32m    957\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInvalid user token. If you didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pass a user token, make sure you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    958\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mare properly logged in by executing `huggingface-cli login`, and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    959\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mif you did pass a user token, double-check it\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms correct.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[39mreturn\u001b[39;00m r\u001b[39m.\u001b[39mjson()\n",
      "\u001b[0;31mHTTPError\u001b[0m: Invalid user token. If you didn't pass a user token, make sure you are properly logged in by executing `huggingface-cli login`, and if you did pass a user token, double-check it's correct."
     ]
    }
   ],
   "source": [
    "notebook_login()\n",
    "# if you want to push to a private repo, simply pass private=True:\n",
    "dataset.push_to_hub(\"imagefolder\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0756ba47183b4cadb9cf0bb12316e2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4859 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# example 1: local folder\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"./finaldata/train_merged/post/\")\n",
    "MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
    "DATASET_ID=\"imagefolder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b759b6172bf4449383962b8b20105402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/4859 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `4`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "Traceback (most recent call last):\n",
      "  File \"train_instruct_pix2pix.py\", line 1, in <module>\n",
      "    from your_dataset_script import DisasterImageDataset\n",
      "ModuleNotFoundError: No module named 'your_dataset_script'\n",
      "Traceback (most recent call last):\n",
      "  File \"train_instruct_pix2pix.py\", line 1, in <module>\n",
      "    from your_dataset_script import DisasterImageDataset\n",
      "ModuleNotFoundError: No module named 'your_dataset_script'\n",
      "Traceback (most recent call last):\n",
      "  File \"train_instruct_pix2pix.py\", line 1, in <module>\n",
      "    from your_dataset_script import DisasterImageDataset\n",
      "ModuleNotFoundError: No module named 'your_dataset_script'\n",
      "Traceback (most recent call last):\n",
      "  File \"train_instruct_pix2pix.py\", line 1, in <module>\n",
      "    from your_dataset_script import DisasterImageDataset\n",
      "ModuleNotFoundError: No module named 'your_dataset_script'\n",
      "[2023-11-09 15:59:06,577] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 1380225) of binary: /home/myid/rk42218/miniconda3/envs/img2img/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 985, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 654, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/run.py\", line 797, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "train_instruct_pix2pix.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2023-11-09_15:59:06\n",
      "  host      : csci-cscuda\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 1380226)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2023-11-09_15:59:06\n",
      "  host      : csci-cscuda\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 1380227)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[3]:\n",
      "  time      : 2023-11-09_15:59:06\n",
      "  host      : csci-cscuda\n",
      "  rank      : 3 (local_rank: 3)\n",
      "  exitcode  : 1 (pid: 1380228)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2023-11-09_15:59:06\n",
      "  host      : csci-cscuda\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 1380225)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# example 1: local folder\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"./finaldata/train_merged/post/\")\n",
    "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
    "DATASET_ID = \"imagefolder\"\n",
    "\n",
    "!accelerate launch --num_processes=1 --num_machines=1 --dynamo_backend=\"no\" --mixed_precision=\"fp16\" --multi_gpu train_instruct_pix2pix.py \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch diffusers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.1\n"
     ]
    }
   ],
   "source": [
    "import diffusers\n",
    "print(diffusers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define the custom dataset class\n",
    "class DisasterImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.image_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.image_frame.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        description = self.image_frame.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, description\n",
    "\n",
    "# Define a transform to preprocess the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((768, 768)), # Resize to the size required by the model\n",
    "    transforms.ToTensor(), # Convert image to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize for pre-trained models\n",
    "])\n",
    "\n",
    "# Create the dataset instances\n",
    "pre_disaster_dataset = DisasterImageDataset(csv_file='./finaldata/train/train_pre_prompts.csv',\n",
    "                                            root_dir='./finaldata/train/pre/',\n",
    "                                            transform=transform)\n",
    "\n",
    "post_disaster_dataset = DisasterImageDataset(csv_file='./finaldata/train/train_post_prompts.csv',\n",
    "                                             root_dir='./finaldata/train/post/',\n",
    "                                             transform=transform)\n",
    "\n",
    "# Parameters for DataLoader\n",
    "batch_size = 4  # Adjust as per your GPU memory\n",
    "num_workers = 2  # Parallel data loading threads, adjust as per your system\n",
    "pin_memory = True  # Recommended when training on GPU\n",
    "\n",
    "# Create DataLoader instances\n",
    "pre_disaster_dataloader = DataLoader(pre_disaster_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                     num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "post_disaster_dataloader = DataLoader(post_disaster_dataset, batch_size=batch_size, shuffle=True,\n",
    "                                      num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "# Now you can iterate over the DataLoader in your training loop\n",
    "for pre_images, pre_descriptions in pre_disaster_dataloader:\n",
    "    # Apply your model to pre_images and pre_descriptions here\n",
    "    pass\n",
    "\n",
    "for post_images, post_descriptions in post_disaster_dataloader:\n",
    "    # Apply your model to post_images and post_descriptions here\n",
    "    pass\n",
    "\n",
    "# Note: You need to run this code in your local machine where the dataset is located.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming the DisasterImageDataset class has been defined as per the previous snippet.\n",
    "\n",
    "# Set the paths to your CSV files and image directories\n",
    "pre_disaster_csv = './finaldata/train/train_pre_prompts.csv'\n",
    "post_disaster_csv = './finaldata/train/train_post_prompts.csv'\n",
    "pre_disaster_dir = './finaldata/train/pre/'\n",
    "post_disaster_dir = './finaldata/train/post/'\n",
    "\n",
    "# Create the dataset instances\n",
    "pre_disaster_dataset = DisasterImageDataset(csv_file=pre_disaster_csv,\n",
    "                                            root_dir=pre_disaster_dir,\n",
    "                                            transform=transform)\n",
    "\n",
    "post_disaster_dataset = DisasterImageDataset(csv_file=post_disaster_csv,\n",
    "                                             root_dir=post_disaster_dir,\n",
    "                                             transform=transform)\n",
    "\n",
    "# Create the DataLoader instances\n",
    "batch_size = 4  # You can modify the batch size according to your system's capabilities\n",
    "\n",
    "pre_disaster_dataloader = DataLoader(pre_disaster_dataset, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=4) # Adjust num_workers based on your system\n",
    "\n",
    "post_disaster_dataloader = DataLoader(post_disaster_dataset, \n",
    "                                      batch_size=batch_size, \n",
    "                                      shuffle=True, \n",
    "                                      num_workers=4) # Adjust num_workers based on your system\n",
    "\n",
    "# Now, you can iterate over the DataLoader in your training loop\n",
    "for pre_images, pre_descriptions in pre_disaster_dataloader:\n",
    "    # Apply your model to pre_images and pre_descriptions here\n",
    "    pass\n",
    "\n",
    "for post_images, post_descriptions in post_disaster_dataloader:\n",
    "    # Apply your model to post_images and post_descriptions here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 3/7 [00:00<00:00,  5.30it/s]`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  3.89it/s]\n",
      "/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 finished\n",
      "Epoch 2/3 finished\n",
      "Epoch 3/3 finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the custom dataset class\n",
    "class DisasterImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.image_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir, self.image_frame.iloc[idx, 0])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        description = self.image_frame.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, description\n",
    "\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize images to fit the model input\n",
    "    transforms.ToTensor(),  # Convert the images to PyTorch tensors\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize images\n",
    "])\n",
    "\n",
    "# Set the paths to your CSV files and image directories\n",
    "pre_disaster_csv = './finaldata/train/train_pre_prompts.csv'\n",
    "post_disaster_csv = './finaldata/train/train_post_prompts.csv'\n",
    "pre_disaster_dir = './finaldata/train/pre/'\n",
    "post_disaster_dir = './finaldata/train/post/'\n",
    "\n",
    "# Create the dataset instances\n",
    "pre_disaster_dataset = DisasterImageDataset(csv_file=pre_disaster_csv,\n",
    "                                            root_dir=pre_disaster_dir,\n",
    "                                            transform=transform)\n",
    "\n",
    "post_disaster_dataset = DisasterImageDataset(csv_file=post_disaster_csv,\n",
    "                                             root_dir=post_disaster_dir,\n",
    "                                             transform=transform)\n",
    "\n",
    "# Create the DataLoader instances\n",
    "batch_size = 4  # You can modify the batch size according to your system's capabilities\n",
    "\n",
    "pre_disaster_dataloader = DataLoader(pre_disaster_dataset, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=True, \n",
    "                                     num_workers=4) # Adjust num_workers based on your system\n",
    "\n",
    "post_disaster_dataloader = DataLoader(post_disaster_dataset, \n",
    "                                      batch_size=batch_size, \n",
    "                                      shuffle=True, \n",
    "                                      num_workers=4) # Adjust num_workers based on your system\n",
    "\n",
    "\n",
    "\n",
    "# Load the pre-trained Stable Diffusion model and components\n",
    "pipeline = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "model = pipeline.unet.to(\"cuda\")\n",
    "\n",
    "# Define an optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Assume a simple loss function for demonstration purposes\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    # Iterate over pre-disaster images and texts\n",
    "    for pre_images, pre_texts in pre_disaster_dataloader:\n",
    "        pre_images = pre_images.to(\"cuda\")\n",
    "        # The texts need to be processed to match the model's expected input format\n",
    "        # Perform the necessary processing here...\n",
    "\n",
    "        # Perform the forward pass, backward pass, optimize, and calculate the loss\n",
    "        # ...\n",
    "\n",
    "    # Iterate over post-disaster images and texts\n",
    "    for post_images, post_texts in post_disaster_dataloader:\n",
    "        post_images = post_images.to(\"cuda\")\n",
    "        # The texts need to be processed to match the model's expected input format\n",
    "        # Perform the necessary processing here...\n",
    "\n",
    "        # Perform the forward pass, backward pass, optimize, and calculate the loss\n",
    "        # ...\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} finished\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./ARL_Course/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/pip/__main__.py\", line 8, in <module>\n",
      "    if sys.path[0] in (\"\", os.getcwd()):\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install diffusers==0.22.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: diffusers\n",
      "Version: 0.23.0.dev0\n",
      "Summary: State-of-the-art diffusion in PyTorch and JAX.\n",
      "Home-page: https://github.com/huggingface/diffusers\n",
      "Author: The HuggingFace team\n",
      "Author-email: patrick@huggingface.co\n",
      "License: Apache\n",
      "Location: /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages\n",
      "Editable project location: /home/myid/rk42218/diffusers\n",
      "Requires: filelock, huggingface-hub, importlib-metadata, numpy, Pillow, regex, requests, safetensors\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show diffusers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package diffusers:\n",
      "\n",
      "NAME\n",
      "    diffusers\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    scripts (package)\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import diffusers\n",
    "help(diffusers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/pip/__main__.py\", line 8, in <module>\n",
      "    if sys.path[0] in (\"\", os.getcwd()):\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter path: /home/myid/rk42218/miniconda3/envs/img2img/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python interpreter path:\", sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Brotli', '1.0.9'), ('Jinja2', '3.1.2'), ('MarkupSafe', '2.1.1'), ('Pillow', '10.0.1'), ('PySocks', '1.7.1'), ('PyWavelets', '1.4.1'), ('PyYAML', '6.0.1'), ('Pygments', '2.15.1'), ('accelerate', '0.24.1'), ('affine', '2.4.0'), ('asttokens', '2.0.5'), ('attrs', '23.1.0'), ('backcall', '0.2.0'), ('certifi', '2023.7.22'), ('cffi', '1.15.1'), ('charset-normalizer', '2.0.4'), ('click', '8.1.7'), ('click-plugins', '1.1.1'), ('cligj', '0.7.2'), ('comm', '0.2.0'), ('cryptography', '41.0.3'), ('debugpy', '1.6.7'), ('decorator', '5.1.1'), ('diffusers', '0.22.1'), ('executing', '0.8.3'), ('filelock', '3.9.0'), ('fsspec', '2023.10.0'), ('gmpy2', '2.1.2'), ('huggingface-hub', '0.17.3'), ('idna', '3.4'), ('imageio', '2.32.0'), ('importlib-metadata', '6.0.0'), ('ipykernel', '6.25.0'), ('ipython', '8.12.2'), ('ipywidgets', '8.1.1'), ('jedi', '0.18.1'), ('joblib', '1.3.2'), ('jupyter-client', '8.5.0'), ('jupyter-core', '5.5.0'), ('jupyterlab-widgets', '3.0.9'), ('lazy-loader', '0.3'), ('matplotlib-inline', '0.1.6'), ('mkl-fft', '1.3.8'), ('mkl-random', '1.2.4'), ('mkl-service', '2.4.0'), ('mpmath', '1.3.0'), ('nest-asyncio', '1.5.6'), ('networkx', '3.1'), ('numpy', '1.24.3'), ('nvidia-cublas-cu12', '12.1.3.1'), ('nvidia-cuda-cupti-cu12', '12.1.105'), ('nvidia-cuda-nvrtc-cu12', '12.1.105'), ('nvidia-cuda-runtime-cu12', '12.1.105'), ('nvidia-cudnn-cu12', '8.9.2.26'), ('nvidia-cufft-cu12', '11.0.2.54'), ('nvidia-curand-cu12', '10.3.2.106'), ('nvidia-cusolver-cu12', '11.4.5.107'), ('nvidia-cusparse-cu12', '12.1.0.106'), ('nvidia-nccl-cu12', '2.18.1'), ('nvidia-nvjitlink-cu12', '12.3.52'), ('nvidia-nvtx-cu12', '12.1.105'), ('packaging', '23.1'), ('pandas', '2.0.3'), ('parso', '0.8.3'), ('pexpect', '4.8.0'), ('pickleshare', '0.7.5'), ('pip', '23.3'), ('platformdirs', '3.10.0'), ('prompt-toolkit', '3.0.36'), ('psutil', '5.9.0'), ('ptyprocess', '0.7.0'), ('pure-eval', '0.2.2'), ('pyOpenSSL', '23.2.0'), ('pycparser', '2.21'), ('pyparsing', '3.1.1'), ('python-dateutil', '2.8.2'), ('pytz', '2023.3.post1'), ('pyzmq', '25.1.0'), ('rasterio', '1.3.9'), ('regex', '2023.10.3'), ('requests', '2.31.0'), ('safetensors', '0.4.0'), ('scikit-image', '0.21.0'), ('scikit-learn', '1.3.2'), ('scipy', '1.10.1'), ('setuptools', '68.0.0'), ('six', '1.16.0'), ('sklearn', '0.0.post11'), ('snuggs', '1.4.7'), ('stack-data', '0.2.0'), ('sympy', '1.11.1'), ('threadpoolctl', '3.2.0'), ('tifffile', '2023.7.10'), ('tokenizers', '0.14.1'), ('torch', '2.1.0'), ('torchaudio', '2.1.0'), ('torchvision', '0.16.0'), ('tornado', '6.3.3'), ('tqdm', '4.66.1'), ('traitlets', '5.7.1'), ('transformers', '4.35.0'), ('triton', '2.1.0'), ('typing-extensions', '4.7.1'), ('tzdata', '2023.3'), ('urllib3', '1.26.18'), ('wcwidth', '0.2.5'), ('wheel', '0.41.2'), ('widgetsnbextension', '4.0.9'), ('zipp', '3.11.0')]\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "installed_packages = [(d.project_name, d.version) for d in pkg_resources.working_set]\n",
    "print(installed_packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusers is installed with version 0.22.1\n"
     ]
    }
   ],
   "source": [
    "diffusers_installed = any(\"diffusers\" == pkg.project_name for pkg in pkg_resources.working_set)\n",
    "if diffusers_installed:\n",
    "    diffusers_version = next((pkg.version for pkg in pkg_resources.working_set if pkg.project_name == \"diffusers\"), \"Unknown version\")\n",
    "    print(f\"Diffusers is installed with version {diffusers_version}\")\n",
    "else:\n",
    "    print(\"Diffusers is not installed in the current environment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.23.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (6.0.0)\n",
      "Requirement already satisfied: filelock in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (0.17.3)\n",
      "Requirement already satisfied: numpy in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (0.4.0)\n",
      "Requirement already satisfied: Pillow in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (10.0.1)\n",
      "Requirement already satisfied: fsspec in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (23.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from importlib-metadata->diffusers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade diffusers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.23.0.dev0)\n",
      "Requirement already satisfied: importlib-metadata in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (6.0.0)\n",
      "Requirement already satisfied: filelock in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (0.17.3)\n",
      "Requirement already satisfied: numpy in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (0.4.0)\n",
      "Requirement already satisfied: Pillow in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (10.0.1)\n",
      "Requirement already satisfied: fsspec in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (23.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from importlib-metadata->diffusers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (8.1.7)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (68.0.0)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: typing-extensions in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (4.7.1)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.12.0 (from wandb)\n",
      "  Downloading protobuf-4.25.0-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: six>=1.4.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.0-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.4/294.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading sentry_sdk-1.34.0-py2.py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, gitdb, GitPython, wandb\n",
      "Successfully installed GitPython-3.1.40 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 protobuf-4.25.0 sentry-sdk-1.34.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in ./miniconda3/envs/img2img/lib/python3.8/site-packages (0.22.1)\n",
      "Requirement already satisfied: transformers in ./miniconda3/envs/img2img/lib/python3.8/site-packages (4.35.0)\n",
      "Requirement already satisfied: Pillow in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (10.0.1)\n",
      "Requirement already satisfied: filelock in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (0.17.3)\n",
      "Requirement already satisfied: importlib-metadata in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (6.0.0)\n",
      "Requirement already satisfied: numpy in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from importlib-metadata->diffusers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install diffusers transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./miniconda3/envs/img2img/lib/python3.8/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: requests in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in ./miniconda3/envs/img2img/lib/python3.8/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipywidgets) (8.12.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: backcall in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: pexpect>4.3 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in ./miniconda3/envs/img2img/lib/python3.8/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda [-h] [-v] [--no-plugins] [-V] COMMAND ...\n",
      "conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'content-trust', 'doctor', 'repoquery', 'env')\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate img2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68bf2bceeec4e73bcc9b97936f51d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 37\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/myid/rk42218/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 46560, done.\u001b[K\n",
      "remote: Counting objects: 100% (3622/3622), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1171/1171), done.\u001b[K\n",
      "remote: Total 46560 (delta 2640), reused 3026 (delta 2143), pack-reused 42938\u001b[K\n",
      "Receiving objects: 100% (46560/46560), 29.30 MiB | 22.75 MiB/s, done.\n",
      "Resolving deltas: 100% (34445/34445), done.\n",
      "/home/myid/rk42218/diffusers\n",
      "Obtaining file:///home/myid/rk42218/diffusers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (6.0.0)\n",
      "Requirement already satisfied: filelock in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.17.3)\n",
      "Requirement already satisfied: numpy in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: Pillow in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (10.0.1)\n",
      "Requirement already satisfied: accelerate>=0.11.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.24.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting protobuf<4,>=3.20.3\n",
      "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard\n",
      "  Downloading tensorboard-2.14.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: Jinja2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate>=0.11.0) (23.1)\n",
      "Requirement already satisfied: psutil in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate>=0.11.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate>=0.11.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate>=0.11.0) (2.1.0)\n",
      "Requirement already satisfied: fsspec in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2) (4.7.1)\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\n",
      "  Downloading pyarrow-14.0.1-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pandas in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.15-py38-none-any.whl.metadata (7.1 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from importlib-metadata) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from Jinja2) (2.1.1)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.59.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard)\n",
      "  Downloading google_auth-2.23.4-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (68.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (0.41.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.3/121.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m266.9/266.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard)\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: sympy in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.11.0) (12.3.52)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate>=0.11.0) (1.3.0)\n",
      "Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.23.4-py2.py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m183.3/183.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.59.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-14.0.1-cp38-cp38-manylinux_2_28_x86_64.whl (38.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m38.1/38.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py38-none-any.whl (132 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Downloading frozenlist-1.4.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (220 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.1/220.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hChecking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: diffusers\n",
      "  Building editable for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.23.0.dev0-0.editable-py3-none-any.whl size=10639 sha256=a8bcd7d66d238fa120ec50124bd077cb43b3a7c1f09b64a288c7609e6f265d60\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-54yqmnwh/wheels/b0/16/a2/4332e9683800dce3c2c92fcbe7dc2dbfcd7fdd05d617648d36\n",
      "Successfully built diffusers\n",
      "Installing collected packages: xxhash, werkzeug, tensorboard-data-server, pyasn1, pyarrow, protobuf, oauthlib, multidict, grpcio, frozenlist, dill, cachetools, async-timeout, absl-py, yarl, rsa, requests-oauthlib, pyasn1-modules, multiprocess, markdown, aiosignal, google-auth, diffusers, aiohttp, google-auth-oauthlib, tensorboard, datasets\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.0\n",
      "    Uninstalling protobuf-4.25.0:\n",
      "      Successfully uninstalled protobuf-4.25.0\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.22.1\n",
      "    Uninstalling diffusers-0.22.1:\n",
      "      Successfully uninstalled diffusers-0.22.1\n",
      "Successfully installed absl-py-2.0.0 aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 cachetools-5.3.2 datasets-2.14.6 diffusers-0.23.0.dev0 dill-0.3.7 frozenlist-1.4.0 google-auth-2.23.4 google-auth-oauthlib-1.0.0 grpcio-1.59.2 markdown-3.5.1 multidict-6.0.4 multiprocess-0.70.15 oauthlib-3.2.2 protobuf-3.20.3 pyarrow-14.0.1 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.0 tensorboard-data-server-0.7.2 werkzeug-3.0.1 xxhash-3.4.1 yarl-1.9.2\n"
     ]
    }
   ],
   "source": [
    "# Login to wandb\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Now, prepare your training script\n",
    "!git clone https://github.com/huggingface/diffusers\n",
    "%cd diffusers\n",
    "!pip install -e \".[training]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd examples/instruct_pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0a248bfb3b40698d864ccea881187d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 152\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y304sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y304sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Define optimizer for the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y304sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer \u001b[39m=\u001b[39m AdamW(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m5e-5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y304sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Fine-tuning loop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y304sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from diffusers import UNet2DConditionModel  # Adjust this based on the correct class\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Create your custom dataset and dataloader\n",
    "train_dataset = DisasterImageDataset(\n",
    "    root_dir='./finaldata/train',\n",
    "    csv_file='./finaldata/train/train_post_prompts.csv',\n",
    "    transform=transform\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Define optimizer for the model\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Fine-tuning loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        prompts = batch['prompt']\n",
    "        # Assuming the model is fine-tuned to generate post-disaster images from prompts\n",
    "        # Forward pass, generate images\n",
    "        generated_images = pipe(prompts).images\n",
    "\n",
    "        # Compute loss between generated_images and batch['post_image']\n",
    "        loss = compute_loss(generated_images, batch['post_image'])\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "pipe.save_pretrained(\"my_finetuned_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.0.dev0\n"
     ]
    }
   ],
   "source": [
    "import diffusers\n",
    "print(diffusers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcf526db68047f7b4288f5f3a604022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 66\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y122sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y122sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Define the optimizer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y122sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y122sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Define the number of epochs for training\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y122sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline\n",
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"  # Replace with the actual model ID\n",
    "#pipe = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "\n",
    "# Move the pipeline to GPU for faster inference if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipe.to(device)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the number of epochs for training\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch in train_loader:\n",
    "        # Get the inputs and labels from the data loader\n",
    "        inputs, labels = batch['pre_image'].to(device), batch['post_image'].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch['pre_image'].to(device), batch['post_image'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            # More code here to calculate validation metrics\n",
    "\n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), 'model_epoch_{}.pth'.format(epoch))\n",
    "\n",
    "# Evaluate the model\n",
    "# Here you would load the best model and evaluate it on a test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0bf703feb745138d9adb177437380e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# This is a general example since the specific class might not be available in your version.\n",
    "# Replace \"DiffusionPipeline\" with the correct class name from your development version if needed.\n",
    "pipe = DiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
    "\n",
    "# Move the pipeline to GPU for faster inference if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipe.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff0b0e76a56414e989f003b85fe2a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline\n",
    "\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\" # <- replace this \n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "generator = torch.Generator(\"cuda\").manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4dd8badf64454cb40099dd6dcac675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.52)\n",
      "Requirement already satisfied: requests in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: diffusers in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.23.0.dev0)\n",
      "Requirement already satisfied: transformers in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (4.35.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (6.0.0)\n",
      "Requirement already satisfied: filelock in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (0.17.3)\n",
      "Requirement already satisfied: numpy in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (0.4.0)\n",
      "Requirement already satisfied: Pillow in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from diffusers) (10.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2->diffusers) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from importlib-metadata->diffusers) (3.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests->diffusers) (2023.7.22)\n",
      "Requirement already satisfied: wandb in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.16.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (1.34.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (68.0.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (4.7.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Login to Hugging Face\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "\n",
    "# Step 2: Install necessary packages (run these commands in your shell)\n",
    "!pip install accelerate\n",
    "!pip install diffusers transformers\n",
    "!pip install wandb\n",
    "\n",
    "# Step 3: Login to wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'diffusers'...\n",
      "remote: Enumerating objects: 46560, done.\u001b[K\n",
      "remote: Counting objects: 100% (3622/3622), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1171/1171), done.\u001b[K\n",
      "remote: Total 46560 (delta 2640), reused 3026 (delta 2143), pack-reused 42938\u001b[K\n",
      "Receiving objects: 100% (46560/46560), 29.30 MiB | 31.59 MiB/s, done.\n",
      "Resolving deltas: 100% (34445/34445), done.\n",
      "/home/myid/rk42218/diffusers/examples/instruct_pix2pix/diffusers\n",
      "Obtaining file:///home/myid/rk42218/diffusers/examples/instruct_pix2pix/diffusers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (6.0.0)\n",
      "Requirement already satisfied: filelock in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.13.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.17.3)\n",
      "Requirement already satisfied: numpy in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.4.0)\n",
      "Requirement already satisfied: Pillow in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (10.0.1)\n",
      "Requirement already satisfied: accelerate>=0.11.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (0.24.1)\n",
      "Requirement already satisfied: datasets in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (2.14.6)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (3.20.3)\n",
      "Requirement already satisfied: tensorboard in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (2.14.0)\n",
      "Requirement already satisfied: Jinja2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate>=0.11.0) (23.1)\n",
      "Requirement already satisfied: psutil in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate>=0.11.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate>=0.11.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from accelerate>=0.11.0) (2.1.0)\n",
      "Requirement already satisfied: fsspec in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from huggingface-hub>=0.13.2) (4.7.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from importlib-metadata) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from Jinja2) (2.1.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (3.5.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (68.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from tensorboard) (0.41.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: sympy in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from torch>=1.10.0->accelerate>=0.11.0) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate>=0.11.0) (12.3.52)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate>=0.11.0) (1.3.0)\n",
      "Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: diffusers\n",
      "  Building editable for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.23.0.dev0-0.editable-py3-none-any.whl size=10664 sha256=4d85a42ca8ea134e4cdd65724d71821563bb7ad0016ffcfb3f8cacd5c5a33dfb\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-i18s3rih/wheels/82/32/48/ad7735257fdd28e7c1ecff626d5b50e0860b88ec0034756afb\n",
      "Successfully built diffusers\n",
      "Installing collected packages: diffusers\n",
      "  Attempting uninstall: diffusers\n",
      "    Found existing installation: diffusers 0.23.0.dev0\n",
      "    Uninstalling diffusers-0.23.0.dev0:\n",
      "      Successfully uninstalled diffusers-0.23.0.dev0\n",
      "Successfully installed diffusers-0.23.0.dev0\n",
      "/home/myid/rk42218/diffusers/examples/instruct_pix2pix/diffusers/examples/instruct_pix2pix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 4: Clone the diffusers repository and install training dependencies\n",
    "!git clone https://github.com/huggingface/diffusers\n",
    "%cd diffusers\n",
    "!pip install -e \".[training]\"\n",
    "\n",
    "# Step 5: Move to the InstructPix2Pix example directory\n",
    "%cd examples/instruct_pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `4`\n",
      "\t\tMore than one GPU was found, enabling multi-GPU training.\n",
      "\t\tIf this was unintended please pass in `--num_processes=1`.\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "usage: train_instruct_pix2pix.py [-h] --pretrained_model_name_or_path\n",
      "                                 PRETRAINED_MODEL_NAME_OR_PATH\n",
      "                                 [--revision REVISION]\n",
      "                                 [--dataset_name DATASET_NAME]\n",
      "                                 [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                                 [--train_data_dir TRAIN_DATA_DIR]\n",
      "                                 [--original_image_column ORIGINAL_IMAGE_COLUMN]\n",
      "                                 [--edited_image_column EDITED_IMAGE_COLUMN]\n",
      "                                 [--edit_prompt_column EDIT_PROMPT_COLUMN]\n",
      "                                 [--val_image_url VAL_IMAGE_URL]\n",
      "                                 [--validation_prompt VALIDATION_PROMPT]\n",
      "                                 [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                                 [--validation_epochs VALIDATION_EPOCHS]\n",
      "                                 [--max_train_samples MAX_TRAIN_SAMPLES]\n",
      "                                 [--output_dir OUTPUT_DIR]\n",
      "                                 [--cache_dir CACHE_DIR] [--seed SEED]\n",
      "                                 [--resolution RESOLUTION] [--center_crop]\n",
      "                                 [--random_flip]\n",
      "                                 [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                                 [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                                 [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                                 [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                                 [--gradient_checkpointing]\n",
      "                                 [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                                 [--lr_scheduler LR_SCHEDULER]\n",
      "                                 [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                                 [--conditioning_dropout_prob CONDITIONING_DROPOUT_PROB]\n",
      "                                 [--use_8bit_adam] [--allow_tf32] [--use_ema]\n",
      "                                 [--non_ema_revision NON_EMA_REVISION]\n",
      "                                 [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                                 [--adam_beta1 ADAM_BETA1]\n",
      "                                 [--adam_beta2 ADAM_BETA2]\n",
      "                                 [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                                 [--adam_epsilon ADAM_EPSILON]\n",
      "                                 [--max_grad_norm MAX_GRAD_NORM]\n",
      "                                 [--push_to_hub] [--hub_token HUB_TOKEN]\n",
      "                                 [--hub_model_id HUB_MODEL_ID]\n",
      "                                 [--logging_dir LOGGING_DIR]\n",
      "                                 [--mixed_precision {no,fp16,bf16}]\n",
      "                                 [--report_to REPORT_TO]\n",
      "                                 [--local_rank LOCAL_RANK]\n",
      "                                 [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                                 [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                                 [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                                 [--enable_xformers_memory_efficient_attention]\n",
      "train_instruct_pix2pix.py: error: argument --push_to_hub: ignored explicit argument 'False'\n",
      "usage: train_instruct_pix2pix.py [-h] --pretrained_model_name_or_path\n",
      "                                 PRETRAINED_MODEL_NAME_OR_PATH\n",
      "                                 [--revision REVISION]\n",
      "                                 [--dataset_name DATASET_NAME]\n",
      "                                 [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                                 [--train_data_dir TRAIN_DATA_DIR]\n",
      "                                 [--original_image_column ORIGINAL_IMAGE_COLUMN]\n",
      "                                 [--edited_image_column EDITED_IMAGE_COLUMN]\n",
      "                                 [--edit_prompt_column EDIT_PROMPT_COLUMN]\n",
      "                                 [--val_image_url VAL_IMAGE_URL]\n",
      "                                 [--validation_prompt VALIDATION_PROMPT]\n",
      "                                 [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                                 [--validation_epochs VALIDATION_EPOCHS]\n",
      "                                 [--max_train_samples MAX_TRAIN_SAMPLES]\n",
      "                                 [--output_dir OUTPUT_DIR]\n",
      "                                 [--cache_dir CACHE_DIR] [--seed SEED]\n",
      "                                 [--resolution RESOLUTION] [--center_crop]\n",
      "                                 [--random_flip]\n",
      "                                 [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                                 [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                                 [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                                 [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                                 [--gradient_checkpointing]\n",
      "                                 [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                                 [--lr_scheduler LR_SCHEDULER]\n",
      "                                 [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                                 [--conditioning_dropout_prob CONDITIONING_DROPOUT_PROB]\n",
      "                                 [--use_8bit_adam] [--allow_tf32] [--use_ema]\n",
      "                                 [--non_ema_revision NON_EMA_REVISION]\n",
      "                                 [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                                 [--adam_beta1 ADAM_BETA1]\n",
      "                                 [--adam_beta2 ADAM_BETA2]\n",
      "                                 [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                                 [--adam_epsilon ADAM_EPSILON]\n",
      "                                 [--max_grad_norm MAX_GRAD_NORM]\n",
      "                                 [--push_to_hub] [--hub_token HUB_TOKEN]\n",
      "                                 [--hub_model_id HUB_MODEL_ID]\n",
      "                                 [--logging_dir LOGGING_DIR]\n",
      "                                 [--mixed_precision {no,fp16,bf16}]\n",
      "                                 [--report_to REPORT_TO]\n",
      "                                 [--local_rank LOCAL_RANK]\n",
      "                                 [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                                 [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                                 [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                                 [--enable_xformers_memory_efficient_attention]\n",
      "train_instruct_pix2pix.py: error: argument --push_to_hub: ignored explicit argument 'False'\n",
      "usage: train_instruct_pix2pix.py [-h] --pretrained_model_name_or_path\n",
      "                                 PRETRAINED_MODEL_NAME_OR_PATH\n",
      "                                 [--revision REVISION]\n",
      "                                 [--dataset_name DATASET_NAME]\n",
      "                                 [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                                 [--train_data_dir TRAIN_DATA_DIR]\n",
      "                                 [--original_image_column ORIGINAL_IMAGE_COLUMN]\n",
      "                                 [--edited_image_column EDITED_IMAGE_COLUMN]\n",
      "                                 [--edit_prompt_column EDIT_PROMPT_COLUMN]\n",
      "                                 [--val_image_url VAL_IMAGE_URL]\n",
      "                                 [--validation_prompt VALIDATION_PROMPT]\n",
      "                                 [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                                 [--validation_epochs VALIDATION_EPOCHS]\n",
      "                                 [--max_train_samples MAX_TRAIN_SAMPLES]\n",
      "                                 [--output_dir OUTPUT_DIR]\n",
      "                                 [--cache_dir CACHE_DIR] [--seed SEED]\n",
      "                                 [--resolution RESOLUTION] [--center_crop]\n",
      "                                 [--random_flip]\n",
      "                                 [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                                 [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                                 [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                                 [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                                 [--gradient_checkpointing]\n",
      "                                 [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                                 [--lr_scheduler LR_SCHEDULER]\n",
      "                                 [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                                 [--conditioning_dropout_prob CONDITIONING_DROPOUT_PROB]\n",
      "                                 [--use_8bit_adam] [--allow_tf32] [--use_ema]\n",
      "                                 [--non_ema_revision NON_EMA_REVISION]\n",
      "                                 [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                                 [--adam_beta1 ADAM_BETA1]\n",
      "                                 [--adam_beta2 ADAM_BETA2]\n",
      "                                 [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                                 [--adam_epsilon ADAM_EPSILON]\n",
      "                                 [--max_grad_norm MAX_GRAD_NORM]\n",
      "                                 [--push_to_hub] [--hub_token HUB_TOKEN]\n",
      "                                 [--hub_model_id HUB_MODEL_ID]\n",
      "                                 [--logging_dir LOGGING_DIR]\n",
      "                                 [--mixed_precision {no,fp16,bf16}]\n",
      "                                 [--report_to REPORT_TO]\n",
      "                                 [--local_rank LOCAL_RANK]\n",
      "                                 [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                                 [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                                 [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                                 [--enable_xformers_memory_efficient_attention]\n",
      "train_instruct_pix2pix.py: error: argument --push_to_hub: ignored explicit argument 'False'\n",
      "usage: train_instruct_pix2pix.py [-h] --pretrained_model_name_or_path\n",
      "                                 PRETRAINED_MODEL_NAME_OR_PATH\n",
      "                                 [--revision REVISION]\n",
      "                                 [--dataset_name DATASET_NAME]\n",
      "                                 [--dataset_config_name DATASET_CONFIG_NAME]\n",
      "                                 [--train_data_dir TRAIN_DATA_DIR]\n",
      "                                 [--original_image_column ORIGINAL_IMAGE_COLUMN]\n",
      "                                 [--edited_image_column EDITED_IMAGE_COLUMN]\n",
      "                                 [--edit_prompt_column EDIT_PROMPT_COLUMN]\n",
      "                                 [--val_image_url VAL_IMAGE_URL]\n",
      "                                 [--validation_prompt VALIDATION_PROMPT]\n",
      "                                 [--num_validation_images NUM_VALIDATION_IMAGES]\n",
      "                                 [--validation_epochs VALIDATION_EPOCHS]\n",
      "                                 [--max_train_samples MAX_TRAIN_SAMPLES]\n",
      "                                 [--output_dir OUTPUT_DIR]\n",
      "                                 [--cache_dir CACHE_DIR] [--seed SEED]\n",
      "                                 [--resolution RESOLUTION] [--center_crop]\n",
      "                                 [--random_flip]\n",
      "                                 [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                                 [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "                                 [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                                 [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                                 [--gradient_checkpointing]\n",
      "                                 [--learning_rate LEARNING_RATE] [--scale_lr]\n",
      "                                 [--lr_scheduler LR_SCHEDULER]\n",
      "                                 [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                                 [--conditioning_dropout_prob CONDITIONING_DROPOUT_PROB]\n",
      "                                 [--use_8bit_adam] [--allow_tf32] [--use_ema]\n",
      "                                 [--non_ema_revision NON_EMA_REVISION]\n",
      "                                 [--dataloader_num_workers DATALOADER_NUM_WORKERS]\n",
      "                                 [--adam_beta1 ADAM_BETA1]\n",
      "                                 [--adam_beta2 ADAM_BETA2]\n",
      "                                 [--adam_weight_decay ADAM_WEIGHT_DECAY]\n",
      "                                 [--adam_epsilon ADAM_EPSILON]\n",
      "                                 [--max_grad_norm MAX_GRAD_NORM]\n",
      "                                 [--push_to_hub] [--hub_token HUB_TOKEN]\n",
      "                                 [--hub_model_id HUB_MODEL_ID]\n",
      "                                 [--logging_dir LOGGING_DIR]\n",
      "                                 [--mixed_precision {no,fp16,bf16}]\n",
      "                                 [--report_to REPORT_TO]\n",
      "                                 [--local_rank LOCAL_RANK]\n",
      "                                 [--checkpointing_steps CHECKPOINTING_STEPS]\n",
      "                                 [--checkpoints_total_limit CHECKPOINTS_TOTAL_LIMIT]\n",
      "                                 [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
      "                                 [--enable_xformers_memory_efficient_attention]\n",
      "train_instruct_pix2pix.py: error: argument --push_to_hub: ignored explicit argument 'False'\n",
      "[2023-11-09 15:28:49,361] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 1379077) of binary: /home/myid/rk42218/miniconda3/envs/img2img/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 985, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/accelerate/commands/launch.py\", line 654, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/run.py\", line 797, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/myid/rk42218/miniconda3/envs/img2img/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 264, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "train_instruct_pix2pix.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2023-11-09_15:28:49\n",
      "  host      : csci-cscuda\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 2 (pid: 1379078)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2023-11-09_15:28:49\n",
      "  host      : csci-cscuda\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 2 (pid: 1379079)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[3]:\n",
      "  time      : 2023-11-09_15:28:49\n",
      "  host      : csci-cscuda\n",
      "  rank      : 3 (local_rank: 3)\n",
      "  exitcode  : 2 (pid: 1379080)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2023-11-09_15:28:49\n",
      "  host      : csci-cscuda\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 2 (pid: 1379077)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_instruct_pix2pix.py \\\n",
    "    --pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\" \\\n",
    "    --train_data_dir=\"./finaldata/train\" \\\n",
    "    --output_dir=\"./output\" \\\n",
    "    --resolution=256 \\\n",
    "    --train_batch_size=4 \\\n",
    "    --gradient_accumulation_steps=16 \\\n",
    "    --learning_rate=5e-06 \\\n",
    "    --num_train_epochs=1 \\\n",
    "    --lr_scheduler_type=\"constant\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --mixed_precision=\"fp16\" \\\n",
    "    --seed=42 \\\n",
    "    --num_processes=4 \\\n",
    "    --push_to_hub=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "CompVis/stable-diffusion-v1-4 does not appear to have a file named config.json. Checkout 'https://huggingface.co/CompVis/stable-diffusion-v1-4/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    262\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/CompVis/stable-diffusion-v1-4/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/utils/hub.py:430\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    431\u001b[0m         path_or_repo_id,\n\u001b[1;32m    432\u001b[0m         filename,\n\u001b[1;32m    433\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    434\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    435\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    436\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    437\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    438\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    439\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    440\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    441\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    442\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    443\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/file_download.py:1232\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1232\u001b[0m     metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1233\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1234\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1235\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1236\u001b[0m         timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1237\u001b[0m     )\n\u001b[1;32m   1238\u001b[0m \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1239\u001b[0m     \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/file_download.py:1608\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1599\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1600\u001b[0m     method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1601\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1606\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m   1607\u001b[0m )\n\u001b[0;32m-> 1608\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1610\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:271\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    270\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEntry Not Found for url: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mraise\u001b[39;00m EntryNotFoundError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGatedRepo\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-654d431b-463faca36982c4e60ecd92f6;5ce93d26-5c6d-46bf-b79d-d380d3a3b493)\n\nEntry Not Found for url: https://huggingface.co/CompVis/stable-diffusion-v1-4/resolve/main/config.json.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 83\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m# Load the pre-trained model and tokenizer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCompVis/stable-diffusion-v1-4\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Replace with the actual model ID\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(model_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m model \u001b[39m=\u001b[39m PNDMPipeline\u001b[39m.\u001b[39mfrom_pretrained(model_id)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#Y152sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m# Move model to GPU if available\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py:733\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mif\u001b[39;00m config_tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 733\u001b[0m         config \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    734\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    735\u001b[0m         )\n\u001b[1;32m    736\u001b[0m     config_tokenizer_class \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mtokenizer_class\n\u001b[1;32m    737\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoTokenizer\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:1048\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1045\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1046\u001b[0m code_revision \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcode_revision\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1048\u001b[0m config_dict, unused_kwargs \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1049\u001b[0m has_remote_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1050\u001b[0m has_local_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/configuration_utils.py:622\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    621\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 622\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    623\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    624\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/configuration_utils.py:677\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m configuration_file \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39m_configuration_file\u001b[39m\u001b[39m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    675\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    676\u001b[0m     \u001b[39m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m    678\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    679\u001b[0m         configuration_file,\n\u001b[1;32m    680\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    681\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    682\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    683\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    684\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    685\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    686\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    687\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    688\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    689\u001b[0m         _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m     commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    692\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     \u001b[39m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    694\u001b[0m     \u001b[39m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/img2img/lib/python3.8/site-packages/transformers/utils/hub.py:481\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[39mif\u001b[39;00m revision \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m         revision \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 481\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    482\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m does not appear to have a file named \u001b[39m\u001b[39m{\u001b[39;00mfull_filename\u001b[39m}\u001b[39;00m\u001b[39m. Checkout \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrevision\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for available files.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    484\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    486\u001b[0m     \u001b[39m# First we try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[1;32m    487\u001b[0m     resolved_file \u001b[39m=\u001b[39m try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir\u001b[39m=\u001b[39mcache_dir, revision\u001b[39m=\u001b[39mrevision)\n",
      "\u001b[0;31mOSError\u001b[0m: CompVis/stable-diffusion-v1-4 does not appear to have a file named config.json. Checkout 'https://huggingface.co/CompVis/stable-diffusion-v1-4/main' for available files."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "# Change the current directory\n",
    "new_directory = \"/home/myid/rk42218/\"\n",
    "os.chdir(new_directory)\n",
    "\n",
    "class DisasterImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images and csv files.\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the pre-disaster image and its path\n",
    "        pre_image_name = self.annotations.iloc[idx, 0].replace('post', 'pre')\n",
    "        pre_image_path = os.path.join(self.root_dir, 'pre', pre_image_name)\n",
    "        pre_image = Image.open(pre_image_path).convert('RGB')\n",
    "        \n",
    "        # Get the post-disaster image and its path\n",
    "        post_image_name = self.annotations.iloc[idx, 0]\n",
    "        post_image_path = os.path.join(self.root_dir, 'post', post_image_name)\n",
    "        post_image = Image.open(post_image_path).convert('RGB')\n",
    "\n",
    "        # Get the corresponding text prompt\n",
    "        prompt = self.annotations.iloc[idx, 1]\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            pre_image = self.transform(pre_image)\n",
    "            post_image = self.transform(post_image)\n",
    "\n",
    "        return {'pre_image': pre_image, 'post_image': post_image, 'prompt': prompt}\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import PNDMPipeline\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Assuming that your script is in the same directory as your datasets\n",
    "root_dir = \"./finaldata\"  # Adjust the path to where your 'finaldata' folder is located\n",
    "\n",
    "# Define your transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create instances of your custom dataset\n",
    "train_dataset = DisasterImageDataset(\n",
    "    root_dir=f\"{root_dir}/train\",\n",
    "    csv_file=f\"{root_dir}/train/train_post_prompts.csv\",\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset = DisasterImageDataset(\n",
    "    root_dir=f\"{root_dir}/val\",\n",
    "    csv_file=f\"{root_dir}/val/val_post_prompts.csv\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Create the corresponding data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"  # Replace with the actual model ID\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = PNDMPipeline.from_pretrained(model_id)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define the training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        # Forward pass\n",
    "        inputs = tokenizer(batch[\"prompt\"], return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "    \n",
    "    # Validation step...\n",
    "    # Save the model at the end of each epoch, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /home/myid/rk42218/diffusers/examples/instruct_pix2pix/diffusers/examples/instruct_pix2pix\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Print the current directory\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the current directory\n",
    "new_directory = \"/home/myid/rk42218/\"\n",
    "os.chdir(new_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create the DataLoader for training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StableDiffusionInstructPix2PixPipeline' from 'diffusers' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/myid/rk42218/model_.ipynb Cell 72\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m StableDiffusionInstructPix2PixPipeline\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Load the pre-trained model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcscuda.cs.uga.edu/home/myid/rk42218/model_.ipynb#X65sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCompVis/stable-diffusion-v1-4\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StableDiffusionInstructPix2PixPipeline' from 'diffusers' (unknown location)"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionInstructPix2PixPipeline\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(pipe.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export DATASET_ID=\"your_dataset_id_here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
